{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f5be4ac1-d0a2-442b-ac57-f7b0c764dae9",
    "_uuid": "876f0b63cba53419fbf7527034bf2c5f93885309"
   },
   "source": [
    "# <center>Freesound General-Purpose Audio Tagging Challenge</center>\n",
    "\n",
    "![Logo](https://upload.wikimedia.org/wikipedia/commons/3/3c/Freesound_project_website_logo.png)\n",
    "\n",
    "Freesound is a collaborative database of Creative Commons Licensed sounds. The aim of this competition is to classify audio files that cover real-world sounds from musical instruments, humans, animals, machines, etc. Few of the labels are: `Trumpet`, `Squeak`, `Meow`, `Applause` and `Finger_sapping`.  One of the challenges is that not all labels are manually verified. A creative solution should be able to partially rely on these *weak* annotations.\n",
    "\n",
    "Let's take a tour of the data visualization and model building through this kernel. If you like this work, please show your support by upvotes. Happy Kaggling!\n",
    "\n",
    "### Contents\n",
    "1. [Exploratory Data Analysis](#eda)\n",
    "    * [Loading data](#loading_data)\n",
    "    * [Distribution of Categories](#distribution)\n",
    "    * [Reading Audio Files](#audio_files)\n",
    "    * [Audio Length](#audio_length)\n",
    "2. [Building a Model using Raw Wave](#1d_model_building)\n",
    "    * [Model Discription](#1d_discription)\n",
    "    * [Configuration](#configuration)\n",
    "    * [DataGenerator class](#data_generator)\n",
    "    * [Normalization](#1d_normalization)\n",
    "    * [Training 1D Conv](#1d_training)\n",
    "    * [Ensembling 1D Conv Predictions](#1d_ensembling)\n",
    "3. [Introduction to MFCC](#intro_mfcc)\n",
    "    * [Generating MFCC using Librosa](#librosa_mfcc)\n",
    "4. [Building a Model using MFCC](#2d_model_building)\n",
    "    * [Preparing Data](#2d_data)\n",
    "    * [Normalization](#2d_normalization)\n",
    "    * [Training 2D Conv on MFCC](#2d_training)\n",
    "    * [Ensembling 2D Conv Predictions](#2d_ensembling)\n",
    "5. [Ensembling 1D Conv and 2D Conv Predictions](#1d_2d_ensembling)\n",
    "6. [Results and Conclusion](#conclusion)\n",
    "\n",
    "\n",
    "<a id=\"eda\"></a>\n",
    "## <center>1. Exploratory Data Analysis</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "39ab28e6-67b2-4129-9dbb-846c81ba85f2",
    "_uuid": "d00095bca1801c4058b75e706058a0651808596f"
   },
   "outputs": [],
   "source": [
    "# Change this to True to replicate the result\n",
    "COMPLETE_RUN = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d4905db9-005f-42f0-aa6b-1408acef7371",
    "_uuid": "4c065a37dd33e869d93ccd8d78daed628e58112b"
   },
   "source": [
    "<a id=\"loading_data\"></a>\n",
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "5abea3ac-4fa5-4c4f-893f-7f2afa49e523",
    "_kg_hide-output": true,
    "_uuid": "337e0950ca948be32d5d881c1a3c675ccf7ac523"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aagnone/anaconda3/envs/dlnd/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1001)\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import IPython\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "97700e3e-82e1-4ce2-9da4-3f8f264e7558",
    "_kg_hide-output": true,
    "_uuid": "2ca1929548de57afb1c4fde19c10f7b18c64264e"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./train.csv\")\n",
    "test = pd.read_csv(\"./sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "a418ce4d-b104-4710-b50d-e9ab1e7e420f",
    "_kg_hide-output": true,
    "_uuid": "1acc16aa65e8f39a5abd8b60906740a671659f1b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>description</th>\n",
       "      <th>manually_verified</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/aagnone/data/dcase2018_gen/wavs/00044347...</td>\n",
       "      <td>Hi-hat</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>00044347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/aagnone/data/dcase2018_gen/wavs/001ca53d...</td>\n",
       "      <td>Saxophone</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>001ca53d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/aagnone/data/dcase2018_gen/wavs/002d256b...</td>\n",
       "      <td>Trumpet</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>002d256b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/aagnone/data/dcase2018_gen/wavs/0033e230...</td>\n",
       "      <td>Glockenspiel</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0033e230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/aagnone/data/dcase2018_gen/wavs/00353774...</td>\n",
       "      <td>Cello</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>00353774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               fname   description  \\\n",
       "0  /home/aagnone/data/dcase2018_gen/wavs/00044347...        Hi-hat   \n",
       "1  /home/aagnone/data/dcase2018_gen/wavs/001ca53d...     Saxophone   \n",
       "2  /home/aagnone/data/dcase2018_gen/wavs/002d256b...       Trumpet   \n",
       "3  /home/aagnone/data/dcase2018_gen/wavs/0033e230...  Glockenspiel   \n",
       "4  /home/aagnone/data/dcase2018_gen/wavs/00353774...         Cello   \n",
       "\n",
       "   manually_verified  label        id  \n",
       "0                  0     23  00044347  \n",
       "1                  1     30  001ca53d  \n",
       "2                  0     38  002d256b  \n",
       "3                  1     19  0033e230  \n",
       "4                  1      6  00353774  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "afceb447-9a8f-4cc4-a7b2-eabc75c3f0aa",
    "_kg_hide-output": true,
    "_uuid": "dad27c6a5ef1fdad658ce710fe16fca58c75a05c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples= 9473   Number of classes= 41\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training examples=\", train.shape[0], \"  Number of classes=\", len(train.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "99b8ebbd-aa18-427a-ab33-e88553a564f6",
    "_kg_hide-output": true,
    "_uuid": "0c3e7629b5e60cfad2a7e1681dcf6e7c55c92e43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23 30 38 19  6 25 21  8  9 24 33 40 26 36 15 29 18 10 37  2  7  3  5 34 31\n",
      " 22 20 28  4 12 32 17 35 11 14 27 13  1  0 39 16]\n"
     ]
    }
   ],
   "source": [
    "print(train.label.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "008c5a97-9c50-4a52-9b65-568986f9bbd6",
    "_uuid": "2edb326e66f4c699bd3cc5ec43279d40e7777180"
   },
   "source": [
    "<a id=\"distribution\"></a>\n",
    "### Distribution of Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "67e5b2e9-cee7-4bf0-84d4-b79bfa6928fd",
    "_uuid": "fef9ca7602b65d3637884eddd38fa5f01a530e81",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7kAAAJjCAYAAADJddY9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nL+gUVSQXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc7b30fbd68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "category_group = train.groupby(['label', 'manually_verified']).count()\n",
    "plot = category_group.unstack().reindex(category_group.unstack().sum(axis=1).sort_values().index)\\\n",
    "          .plot(kind='bar', stacked=True, title=\"Number of Audio Samples per Category\", figsize=(16,10))\n",
    "plot.set_xlabel(\"Category\")\n",
    "plot.set_ylabel(\"Number of Samples\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "29538dc2-387a-4910-a203-f105c97ce0e6",
    "_kg_hide-output": true,
    "_uuid": "c2ca61efa1696baa87f831f7df927fd1cba7abbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum samples per category =  94\n",
      "Maximum samples per category =  300\n"
     ]
    }
   ],
   "source": [
    "print('Minimum samples per category = ', min(train.label.value_counts()))\n",
    "print('Maximum samples per category = ', max(train.label.value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a715d812-98fc-459a-8695-13940b2ca1de",
    "_uuid": "d0ed18e06d39f962d1a2a58f4743171c9c4970e9"
   },
   "source": [
    "We observe that:\n",
    "1. The number of audio samples per category is **non-nform**. The minimum number of audio samples in a category is `94` while the maximum is `300`\n",
    "2. Also, the proportion of `maually_verified` labels per category is non-uniform.\n",
    "<a id=\"audio_files\"></a>\n",
    "### Reading Audio Files\n",
    "\n",
    "The audios are [Pulse-code modulated](https://en.wikipedia.org/wiki/Audio_bit_depth) with a [bit depth](https://en.wikipedia.org/wiki/Audio_bit_depth) of 16 and a [sampling rate](https://en.wikipedia.org/wiki/Sampling_%28signal_processing%29) of 44.1 kHz\n",
    "\n",
    "![16-bit PCM](https://upload.wikimedia.org/wikipedia/commons/thumb/b/bf/Pcm.svg/500px-Pcm.svg.png)\n",
    "\n",
    "* **Bit-depth = 16**: The amplitude of each sample in the audio is one of 2^16 (=65536) possible values. \n",
    "* **Samplig rate = 44.1 kHz**: Each second in the audio consists of 44100 samples. So, if the duration of the audio file is 3.2 seconds, the audio will consist of 44100\\*3.2 = 141120 values.\n",
    "\n",
    "Let's listen to an audio file in our dataset and load it to a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "20d2c517-01f9-46a9-b339-6ce415bc59d2",
    "_uuid": "e15d81dcb2a4433b94182eb588ccb183e27fa700"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '/home/aagnone/data/dcase2018_gen/00044347.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-62806f84d118>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mipd\u001b[0m  \u001b[0;31m# To play sound in the notebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/aagnone/data/dcase2018_gen/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'00044347.wav'\u001b[0m   \u001b[0;31m# Hi-hat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mipd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAudio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/dlnd/lib/python3.6/site-packages/IPython/lib/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, filename, url, embed, rate, autoplay)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dlnd/lib/python3.6/site-packages/IPython/lib/display.py\u001b[0m in \u001b[0;36m_make_wav\u001b[0;34m(self, data, rate)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0mnchan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '/home/aagnone/data/dcase2018_gen/00044347.wav'"
     ]
    }
   ],
   "source": [
    "import IPython.display as ipd  # To play sound in the notebook\n",
    "fname = '/home/aagnone/data/dcase2018_gen/' + '00044347.wav'   # Hi-hat\n",
    "ipd.Audio(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "efe10cb8-13f1-405e-8b71-ca5758ee18d4",
    "_uuid": "101f9997c5c8cd0392c1f367684331d3f6e80422"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input/freesound-audio-tagging/audio_train/00044347.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-867a3418315f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Using wave library\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwave\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mwav\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwave\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sampling (frame) rate = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwav\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetframerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total samples (frames) = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwav\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetnframes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dlnd/lib/python3.6/wave.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(f, mode)\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mWave_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mWave_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dlnd/lib/python3.6/wave.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_i_opened_the_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_i_opened_the_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;31m# else, assume it is an open file object already\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/freesound-audio-tagging/audio_train/00044347.wav'"
     ]
    }
   ],
   "source": [
    "# Using wave library\n",
    "import wave\n",
    "wav = wave.open(fname)\n",
    "print(\"Sampling (frame) rate = \", wav.getframerate())\n",
    "print(\"Total samples (frames) = \", wav.getnframes())\n",
    "print(\"Duration = \", wav.getnframes()/wav.getframerate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3c9f1564-fa50-4f4b-87d9-2070fc44770d",
    "_uuid": "e4ea69354f032c0b511b50693c750e19fb4f6cb3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using scipy\n",
    "from scipy.io import wavfile\n",
    "rate, data = wavfile.read(fname)\n",
    "print(\"Sampling (frame) rate = \", rate)\n",
    "print(\"Total samples (frames) = \", data.shape)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3c6c2a6f-4914-4e13-84be-6b8492487c7b",
    "_uuid": "bacb576c223074c03d0cb5c55b917df2e1261498"
   },
   "source": [
    "Let's plot the audio frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "eeb3e8ab-106f-4e67-84fd-7bf8c9847c8e",
    "_uuid": "a1e25d48f74b38784d7588e5c33af9b03248e7d3",
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(data, '-', );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79293dfd-e254-47f3-8909-ff32f08f87aa",
    "_uuid": "762301b9c5d7653d761205e172ff3da88745400f"
   },
   "source": [
    "Let's zoom in on first 1000 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bfb06a3e-b501-4570-89ea-008781414144",
    "_uuid": "7c1b21e52e83d0bc723a48a32ced87445a540fa9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 4))\n",
    "plt.plot(data[:500], '.'); plt.plot(data[:500], '-');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "42761f3d-0d20-4a97-843a-02186299f76b",
    "_uuid": "b3a730fc5ee4a9ab5904cddda84a05ac118c749d"
   },
   "source": [
    "<a id=\"audio_length\"></a>\n",
    "### Audio Length\n",
    "\n",
    "We shall now analyze the lengths of the audio files in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "40b7ba05-45df-4779-be29-b177b9b9b8e1",
    "_uuid": "867f0074922314b78de6bd9d14b308b634d1fbbe",
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/aagnone/data/dcase2018_gen/wavs/00063640.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-f072c7877f26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nframes'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fname'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwave\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetnframes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nframes'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fname'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwave\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/aagnone/data/dcase2018_gen/wavs/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetnframes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviolinplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"nframes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dlnd/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   2508\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2509\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2510\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2512\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-f072c7877f26>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nframes'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fname'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwave\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetnframes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nframes'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fname'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwave\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/aagnone/data/dcase2018_gen/wavs/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetnframes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviolinplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"nframes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dlnd/lib/python3.6/wave.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(f, mode)\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mWave_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mWave_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dlnd/lib/python3.6/wave.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_i_opened_the_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_i_opened_the_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;31m# else, assume it is an open file object already\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/aagnone/data/dcase2018_gen/wavs/00063640.wav'"
     ]
    }
   ],
   "source": [
    "train['nframes'] = train['fname'].apply(lambda f: wave.open(f).getnframes())\n",
    "test['nframes'] = test['fname'].apply(lambda f: wave.open('/home/aagnone/data/dcase2018_gen/wavs/' + f).getnframes())\n",
    "\n",
    "_, ax = plt.subplots(figsize=(16, 4))\n",
    "sns.violinplot(ax=ax, x=\"label\", y=\"nframes\", data=train)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Distribution of audio frames, per label', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fa8fa2bd-359c-4f53-b94b-67a6c1acde64",
    "_uuid": "92ea60bb1827c9ec4dd261d015739dde762f9b18"
   },
   "source": [
    "We observe:\n",
    "1. The distribution of audio length across labels is non-uniform and has high variance.\n",
    "\n",
    "Let's now analyze the frame length distribution in Train and Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e49045f1-7c44-4f1a-b740-d45ec3b6b321",
    "_uuid": "0ec5676601b04e3fdbae4052122c9db1a68251a9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16,5))\n",
    "train.nframes.hist(bins=100, ax=axes[0])\n",
    "test.nframes.hist(bins=100, ax=axes[1])\n",
    "plt.suptitle('Frame Length Distribution in Train and Test', ha='center', fontsize='large');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "72c8dc2d-8385-4f74-8820-8d805fee8dc0",
    "_uuid": "3e517330a7209f25fa69056db1214f27fb585824"
   },
   "source": [
    "We observe:\n",
    "1. Majority of the audio files are short.\n",
    "1. There are four `abnormal` length in the test histogram. Let's analyze them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f36e006f-fb47-4134-94a8-aede32f770ad",
    "_uuid": "8495f1f7fdaffa09623458aa66803c6a2e156537",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "abnormal_length = [707364, 353682, 138474, 184338]\n",
    "\n",
    "for length in abnormal_length:\n",
    "    abnormal_fnames = test.loc[test.nframes == length, 'fname'].values\n",
    "    print(\"Frame length = \", length, \" Number of files = \", abnormal_fnames.shape[0], end=\"   \")\n",
    "    fname = np.random.choice(abnormal_fnames)\n",
    "    print(\"Playing \", fname)\n",
    "    IPython.display.display(ipd.Audio( '../input/freesound-audio-tagging/audio_test/' + fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "146baca0-66cc-4ce1-8d16-16ae5764a354",
    "_uuid": "64462b38a986a2f40deeb6a053b9d99d8f6993b5"
   },
   "source": [
    "<a id=\"1d_model_building\"></a>\n",
    "## <center>2. Building a Model using Raw Wave</center>\n",
    "We will build two models:\n",
    "1. The first model will take the raw audio (1D array) as input and the primary operation will be Conv1D\n",
    "2. The second model will take the MFCCs as input. (We will explain MFCC later)\n",
    "\n",
    "<a id=\"1d_discription\"></a>\n",
    "### Keras Model using raw wave\n",
    "\n",
    "Our model has the architecture as follows:\n",
    "![raw](https://raw.githubusercontent.com/zaffnet/images/master/images/raw_model.jpg)\n",
    "\n",
    "**Important:**\n",
    "Due to the time limit on Kaggle Kernels, it is not possible to perform 10-fold training of a large model. I have trained the model locally and uploaded its output files as a dataset. If you wish to train the bigger model, change `COMPLETE_RUN = True` at the beginning of the kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0ef1062c-be8a-4021-a50a-3df9bacd30fc",
    "_uuid": "2df0e6e509896eaefd30f6b4c15b55736760aafa",
    "collapsed": true
   },
   "source": [
    "#### Some sssential imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "58fbb75c-1ef8-478f-a5fd-3fe6cfda32af",
    "_kg_hide-output": true,
    "_uuid": "36454f818dcbe02852e7a639d428a004a387ce9f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import scipy\n",
    "from keras import losses, models, optimizers\n",
    "from keras.activations import relu, softmax\n",
    "from keras.callbacks import (EarlyStopping, LearningRateScheduler,\n",
    "                             ModelCheckpoint, TensorBoard, ReduceLROnPlateau)\n",
    "from keras.layers import (Convolution1D, Dense, Dropout, GlobalAveragePooling1D, \n",
    "                          GlobalMaxPool1D, Input, MaxPool1D, concatenate)\n",
    "from keras.utils import Sequence, to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "64df4fea-4917-4762-b9be-68163f590c13",
    "_uuid": "927b4d615e24291f3c9510b653e723dc031fd042"
   },
   "source": [
    "<a id=\"configuration\"></a>\n",
    "#### Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1dda9e10-5b51-430a-b20d-a319695df25d",
    "_uuid": "a9dc3968c8915e1d96f0bc011e67db26932ab0a3"
   },
   "source": [
    "The Configuration object stores those learning parameters that are shared between data generators, models, and training functions. Anything that is `global` as far as the training is concerned can become the part of Configuration object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e0836104-1a4d-485d-9cc1-3e5b82f449de",
    "_uuid": "66640745984135b853d36eac127fb2da302319ad",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    def __init__(self,\n",
    "                 sampling_rate=16000, audio_duration=2, n_classes=41,\n",
    "                 use_mfcc=False, n_folds=10, learning_rate=0.0001, \n",
    "                 max_epochs=50, n_mfcc=20):\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.audio_duration = audio_duration\n",
    "        self.n_classes = n_classes\n",
    "        self.use_mfcc = use_mfcc\n",
    "        self.n_mfcc = n_mfcc\n",
    "        self.n_folds = n_folds\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_epochs = max_epochs\n",
    "\n",
    "        self.audio_length = self.sampling_rate * self.audio_duration\n",
    "        if self.use_mfcc:\n",
    "            self.dim = (self.n_mfcc, 1 + int(np.floor(self.audio_length/512)), 1)\n",
    "        else:\n",
    "            self.dim = (self.audio_length, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dbdcf3fb-f915-482c-ad8f-d8578de8f080",
    "_uuid": "b1a794352ac7505abcf212d1b1c6deef32178ab3",
    "collapsed": true
   },
   "source": [
    "<a id=\"data_generator\"></a>\n",
    "#### DataGenerator Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "059d4658-f1a4-4d6a-ae67-05140fc9bac6",
    "_uuid": "f1a0716a545ade83970005951719e71cebe35ab2"
   },
   "source": [
    "The DataGenerator class inherits from **`keras.utils.Sequence`** . It is useful for preprocessing and feeding the data to a Keras model. \n",
    "* Once initialized with a batch_size, it computes the number of batches in an epoch. The **`__len__`** method tells Keras how many batches to draw in each epoch. \n",
    "* The **`__getitem__`** method takes an index (which is the batch number) and returns a batch of the data (both X and y) after calculating the offset. During test time, only `X` is returned.\n",
    "* If we want to perform some action after each epoch (like shuffle the data, or increase the proportion of augmented data), we can use the **`on_epoch_end`** method.\n",
    "\n",
    "Note:\n",
    "**`Sequence`** are a safer way to do multiprocessing. This structure guarantees that the network will only train once on each sample per epoch which is not the case with generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f9d14e7d-89d8-42f0-9eb3-f895645b2de2",
    "_uuid": "aca30bc0f6fccf71e4b9a68e5c04c1aaf950b169",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, config, data_dir, list_IDs, labels=None, \n",
    "                 batch_size=64, preprocessing_fn=lambda x: x):\n",
    "        self.config = config\n",
    "        self.data_dir = data_dir\n",
    "        self.list_IDs = list_IDs\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.preprocessing_fn = preprocessing_fn\n",
    "        self.on_epoch_end()\n",
    "        self.dim = self.config.dim\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "        return self.__data_generation(list_IDs_temp)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        cur_batch_size = len(list_IDs_temp)\n",
    "        X = np.empty((cur_batch_size, *self.dim))\n",
    "\n",
    "        input_length = self.config.audio_length\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            file_path = self.data_dir + ID\n",
    "            \n",
    "            # Read and Resample the audio\n",
    "            data, _ = librosa.core.load(file_path, sr=self.config.sampling_rate,\n",
    "                                        res_type='kaiser_fast')\n",
    "\n",
    "            # Random offset / Padding\n",
    "            if len(data) > input_length:\n",
    "                max_offset = len(data) - input_length\n",
    "                offset = np.random.randint(max_offset)\n",
    "                data = data[offset:(input_length+offset)]\n",
    "            else:\n",
    "                if input_length > len(data):\n",
    "                    max_offset = input_length - len(data)\n",
    "                    offset = np.random.randint(max_offset)\n",
    "                else:\n",
    "                    offset = 0\n",
    "                data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n",
    "                \n",
    "            # Normalization + Other Preprocessing\n",
    "            if self.config.use_mfcc:\n",
    "                data = librosa.feature.mfcc(data, sr=self.config.sampling_rate,\n",
    "                                                   n_mfcc=self.config.n_mfcc)\n",
    "                data = np.expand_dims(data, axis=-1)\n",
    "            else:\n",
    "                data = self.preprocessing_fn(data)[:, np.newaxis]\n",
    "            X[i,] = data\n",
    "\n",
    "        if self.labels is not None:\n",
    "            y = np.empty(cur_batch_size, dtype=int)\n",
    "            for i, ID in enumerate(list_IDs_temp):\n",
    "                y[i] = self.labels[ID]\n",
    "            return X, to_categorical(y, num_classes=self.config.n_classes)\n",
    "        else:\n",
    "            return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "49a23330-291d-4eb7-aeb9-4abcfd648277",
    "_uuid": "6b69d10980c7aad004c6a7fa860c649d0b875a0f"
   },
   "source": [
    "<a id=\"1d_normalization\"></a>\n",
    "#### Normalization\n",
    "\n",
    "Normalization is a crucial preprocessing step. The simplest method is rescaling the range of features to scale the range in [0, 1]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bb5936dd-5fb1-4894-8165-6daf372a6832",
    "_uuid": "c9db10ad526815730a6e5a1f057de8c9bff12615",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def audio_norm(data):\n",
    "    max_data = np.max(data)\n",
    "    min_data = np.min(data)\n",
    "    data = (data-min_data)/(max_data-min_data+1e-6)\n",
    "    return data-0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3b9656b0-31d3-47ea-9bb3-789a40026793",
    "_uuid": "c2f0bbd810926b309d3b02473e937a2a86bc9005"
   },
   "source": [
    "* The dummy model is just for debugging purpose.\n",
    "* Our 1D Conv model is fairly deep and is trained using Adam Optimizer with a learning rate of 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "245887b3-a0dc-498d-900c-dd1c2898d955",
    "_uuid": "40771630994b93eee040c239f1c0e3bf88f13ced",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_1d_dummy_model(config):\n",
    "    \n",
    "    nclass = config.n_classes\n",
    "    input_length = config.audio_length\n",
    "    \n",
    "    inp = Input(shape=(input_length,1))\n",
    "    x = GlobalMaxPool1D()(inp)\n",
    "    out = Dense(nclass, activation=softmax)(x)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=out)\n",
    "    opt = optimizers.Adam(config.learning_rate)\n",
    "\n",
    "    model.compile(optimizer=opt, loss=losses.categorical_crossentropy, metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "def get_1d_conv_model(config):\n",
    "    \n",
    "    nclass = config.n_classes\n",
    "    input_length = config.audio_length\n",
    "    \n",
    "    inp = Input(shape=(input_length,1))\n",
    "    x = Convolution1D(16, 9, activation=relu, padding=\"valid\")(inp)\n",
    "    x = Convolution1D(16, 9, activation=relu, padding=\"valid\")(x)\n",
    "    x = MaxPool1D(16)(x)\n",
    "    x = Dropout(rate=0.1)(x)\n",
    "    \n",
    "    x = Convolution1D(32, 3, activation=relu, padding=\"valid\")(x)\n",
    "    x = Convolution1D(32, 3, activation=relu, padding=\"valid\")(x)\n",
    "    x = MaxPool1D(4)(x)\n",
    "    x = Dropout(rate=0.1)(x)\n",
    "    \n",
    "    x = Convolution1D(32, 3, activation=relu, padding=\"valid\")(x)\n",
    "    x = Convolution1D(32, 3, activation=relu, padding=\"valid\")(x)\n",
    "    x = MaxPool1D(4)(x)\n",
    "    x = Dropout(rate=0.1)(x)\n",
    "    \n",
    "    x = Convolution1D(256, 3, activation=relu, padding=\"valid\")(x)\n",
    "    x = Convolution1D(256, 3, activation=relu, padding=\"valid\")(x)\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "\n",
    "    x = Dense(64, activation=relu)(x)\n",
    "    x = Dense(1028, activation=relu)(x)\n",
    "    out = Dense(nclass, activation=softmax)(x)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=out)\n",
    "    opt = optimizers.Adam(config.learning_rate)\n",
    "\n",
    "    model.compile(optimizer=opt, loss=losses.categorical_crossentropy, metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2e67aa4a-f2d0-4889-a1da-b6d3217edb5e",
    "_uuid": "32afe89ebdee366de311a6fffb5c49a0e568aaa8"
   },
   "source": [
    "<a id=\"1d_training\"></a>\n",
    "#### Training 1D Conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a93de421-33be-4104-bcfa-b581cbde3d75",
    "_uuid": "ddbcf58975c5cd7436314a77e5b8f938640bcf34"
   },
   "source": [
    "It is important to convert raw labels to integer indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e9027035-0e77-47dd-8616-113c1cfb37e0",
    "_uuid": "53aca10261dea0b8357e39adb513c7689b7c07ff",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LABELS = list(train.label.unique())\n",
    "label_idx = {label: i for i, label in enumerate(LABELS)}\n",
    "train.set_index(\"fname\", inplace=True)\n",
    "test.set_index(\"fname\", inplace=True)\n",
    "train[\"label_idx\"] = train.label.apply(lambda x: label_idx[x])\n",
    "if not COMPLETE_RUN:\n",
    "    train = train[:2000]\n",
    "    test = test[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f2f2dc50-77d3-43ba-bf7f-3c6b39beb67b",
    "_uuid": "604a3c7971599898b5614a67da12da84ab651a55",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = Config(sampling_rate=16000, audio_duration=2, n_folds=10, learning_rate=0.001)\n",
    "if not COMPLETE_RUN:\n",
    "    config = Config(sampling_rate=100, audio_duration=1, n_folds=2, max_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e31b98ec-cecb-4584-9bbc-bc2748476b49",
    "_uuid": "7a2a5e44d82a2b9e04117b76464225278ec4a1d8"
   },
   "source": [
    "Here is the code for 10-fold training:\n",
    "* We use **`from sklearn.cross_validation.StratifiedKFold`** for splitting the trainig data into 10 folds.\n",
    "* We use some Keras callbacks to monitor the training.\n",
    "    * **`ModelCheckpoint`** saves the best weight of our model (using validation data). We use this weight to make test predictions.\n",
    "    * **`EarlyStopping`** stops the training once validation loss ceases to decrease\n",
    "    * **`TensorBoard`** helps us visualize training and validation loss and accuracy.\n",
    "* We fit the model using **`DataGenerator`** for training and validation splits. \n",
    "* We get both training and test predictions and save them as .npy format. We also generate a submission file. For 10-fold CV, the number of prediction files should be 10. We will ensemble these predictions later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e81537d9-d886-4bd5-a923-7efe1aa1812d",
    "_kg_hide-output": true,
    "_uuid": "1e68d5ae8e431445151c8c7744fadb65fbf692c8",
    "collapsed": true
   },
   "source": [
    "```python\n",
    "PREDICTION_FOLDER = \"predictions_1d_conv\"\n",
    "if not os.path.exists(PREDICTION_FOLDER):\n",
    "    os.mkdir(PREDICTION_FOLDER)\n",
    "if os.path.exists('logs/' + PREDICTION_FOLDER):\n",
    "    shutil.rmtree('logs/' + PREDICTION_FOLDER)\n",
    "\n",
    "skf = StratifiedKFold(train.label_idx, n_folds=config.n_folds)\n",
    "\n",
    "for i, (train_split, val_split) in enumerate(skf):\n",
    "    train_set = train.iloc[train_split]\n",
    "    val_set = train.iloc[val_split]\n",
    "    checkpoint = ModelCheckpoint('best_%d.h5'%i, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n",
    "    tb = TensorBoard(log_dir='./logs/' + PREDICTION_FOLDER + '/fold_%d'%i, write_graph=True)\n",
    "\n",
    "    callbacks_list = [checkpoint, early, tb]\n",
    "    print(\"Fold: \", i)\n",
    "    print(\"#\"*50)\n",
    "    if COMPLETE_RUN:\n",
    "        model = get_1d_conv_model(config)\n",
    "    else:\n",
    "        model = get_1d_dummy_model(config)\n",
    "\n",
    "    train_generator = DataGenerator(config, '../input/freesound-audio-tagging/audio_train/', train_set.index, \n",
    "                                    train_set.label_idx, batch_size=64,\n",
    "                                    preprocessing_fn=audio_norm)\n",
    "    val_generator = DataGenerator(config, '../input/freesound-audio-tagging/audio_train/', val_set.index, \n",
    "                                  val_set.label_idx, batch_size=64,\n",
    "                                  preprocessing_fn=audio_norm)\n",
    "    \n",
    "    history = model.fit_generator(train_generator, callbacks=callbacks_list, validation_data=val_generator,\n",
    "                                  epochs=config.max_epochs, use_multiprocessing=True, workers=6, max_queue_size=20)\n",
    "    \n",
    "    model.load_weights('best_%d.h5'%i)\n",
    "    \n",
    "    # Save train predictions\n",
    "    train_generator = DataGenerator(config, '../input/freesound-audio-tagging/audio_train/', train.index, batch_size=128,\n",
    "                                    preprocessing_fn=audio_norm)\n",
    "    predictions = model.predict_generator(train_generator, use_multiprocessing=True, \n",
    "                                          workers=6, max_queue_size=20, verbose=1)\n",
    "    np.save(PREDICTION_FOLDER + \"/train_predictions_%d.npy\"%i, predictions)\n",
    "    \n",
    "    # Save test predictions\n",
    "    test_generator = DataGenerator(config, '../input/freesound-audio-tagging/audio_test/', test.index, batch_size=128,\n",
    "                                    preprocessing_fn=audio_norm)\n",
    "    predictions = model.predict_generator(test_generator, use_multiprocessing=True, \n",
    "                                          workers=6, max_queue_size=20, verbose=1)\n",
    "    np.save(PREDICTION_FOLDER + \"/test_predictions_%d.npy\"%i, predictions)\n",
    "    \n",
    "    # Make a submission file\n",
    "    top_3 = np.array(LABELS)[np.argsort(-predictions, axis=1)[:, :3]]\n",
    "    predicted_labels = [' '.join(list(x)) for x in top_3]\n",
    "    test['label'] = predicted_labels\n",
    "    test[['label']].to_csv(PREDICTION_FOLDER + \"/predictions_%d.csv\"%i)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "488df4a9-b090-4397-a649-2e94f9ee82ad",
    "_uuid": "2afcdcf0f77f8685f57e2d119ec0cc650b7255d7"
   },
   "source": [
    "<a id=\"1d_ensembling\"></a>\n",
    "#### Ensembling 1D Conv Predictions\n",
    "Now that we have trained our model, it is time average the predictions of 10-folds. We will try Geometric Mean averaging and see what will be our Public LB score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4050aede-678b-4f9e-bb95-e70f79e4f6bd",
    "_kg_hide-output": true,
    "_uuid": "bfdddecb92be07d06e71d25b1812d064a0cee66d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_list = []\n",
    "for i in range(10):\n",
    "    pred_list.append(np.load(\"../input/freesound-prediction-file/test_predictions_%d.npy\"%i))\n",
    "prediction = np.ones_like(pred_list[0])\n",
    "for pred in pred_list:\n",
    "    prediction = prediction*pred\n",
    "prediction = prediction**(1./len(pred_list))\n",
    "# Make a submission file\n",
    "top_3 = np.array(LABELS)[np.argsort(-prediction, axis=1)[:, :3]]\n",
    "predicted_labels = [' '.join(list(x)) for x in top_3]\n",
    "test = pd.read_csv('../input/freesound-audio-tagging/sample_submission.csv')\n",
    "test['label'] = predicted_labels\n",
    "test[['fname', 'label']].to_csv(\"1d_conv_ensembled_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8c437de1-ecc0-4c72-9595-c689c101a72c",
    "_uuid": "40ef0374888d1453eed07c8daa18f231c12ef36d"
   },
   "source": [
    "<a id=\"intro_mfcc\"></a>\n",
    "## <center> 3. Introuction to MFCC\n",
    "\n",
    "As we have seen in the previous section, our Deep Learning models are powerful enough to classify sounds from the raw audio. We do not require any complex feature engineering. But before the Deep Learning era, people developed techniques to extract features from audio signals. It turns out that these techniques are still useful. One such technique is computing the MFCC (Mel Frquency Cepstral Coefficients) from the raw audio. Before we jump to MFCC, let's talk about extracting features from the sound.\n",
    "\n",
    "If we just want to classify some sound, we should build features that are **speaker independent**. Any feature that only gives information about the speaker (like the pitch of their voice) will not be helpful for classification. In other words, we should extract features that depend on the \"content\" of the audio rather than the nature of the speaker. Also, a good feature extraction technique should mimic the human speech perception. We don't hear loudness on a linear scale. If we want to double the perceived loudness of a sound, we have to put 8 times as much energy into it. Instead of a linear scale, our perception system uses a log scale. \n",
    "\n",
    "Taking these things into account, Davis and Mermelstein came up with MFCC in the 1980's. MFCC mimics the logarithmic perception of loudness and pitch of human auditory system and tries to eliminate speaker dependent characteristics by excluding the fundamental frequency and their harmonics. The underlying mathematics is quite complicated and we will skip that. For those interested, here is the [detailed explanation](http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/).\n",
    "\n",
    "![http://recognize-speech.com/images/FeatureExtraction/MFCC/MFCC_Flowchart.png](http://recognize-speech.com/images/FeatureExtraction/MFCC/MFCC_Flowchart.png)\n",
    "\n",
    "<a id=\"librosa_mfcc\"></a>\n",
    "#### Generating MFCC using Librosa\n",
    "The library librosa has a function to calculate MFCC. Let's compute the MFCC of an audio file and visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "dcb2a6e7-b086-4d1a-94a4-215f2cb101d0",
    "_uuid": "2f8dfd08f109ababeaca9ce900b68b8a716d28b7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "SAMPLE_RATE = 44100\n",
    "fname = '../input/freesound-audio-tagging/audio_train/' + '00044347.wav'   # Hi-hat\n",
    "wav, _ = librosa.core.load(fname, sr=SAMPLE_RATE)\n",
    "wav = wav[:2*44100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6250242e-e3c5-4cb9-8405-43d3279dada1",
    "_kg_hide-output": true,
    "_uuid": "7498089442d866816aabc85234a8a5546c5e58da",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mfcc = librosa.feature.mfcc(wav, sr = SAMPLE_RATE, n_mfcc=40)\n",
    "mfcc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d02be92a-f208-42c2-ac4a-e0b2b22ba195",
    "_uuid": "f4054a6856eaa16cf82cacb5bd08ea53cdab386b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(mfcc, cmap='hot', interpolation='nearest');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5015b22f-5de8-4a86-aef4-074bf90023aa",
    "_uuid": "59502f44b22674250a047e89b610867d6c6306c3"
   },
   "source": [
    "<a id=\"2d_model_building\"></a>\n",
    "## <center>4. Building a Model using MFCC\n",
    "\n",
    "We will build now build a 2D Convolutional model using MFCC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "384fe65d-fe10-4eee-826c-75c4dffcfa2d",
    "_kg_hide-output": true,
    "_uuid": "ed54039a4e0b91d10f603799feb8166404bbceec",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import (Convolution2D, GlobalAveragePooling2D, BatchNormalization, Flatten,\n",
    "                          GlobalMaxPool2D, MaxPool2D, concatenate, Activation)\n",
    "from keras.utils import Sequence, to_categorical\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "97d07753-d78d-465d-936d-7f03eaf1def1",
    "_uuid": "0b2ac601f52ae4ed9dc849fcd095ab94cfe878fe",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_2d_dummy_model(config):\n",
    "    \n",
    "    nclass = config.n_classes\n",
    "    \n",
    "    inp = Input(shape=(config.dim[0],config.dim[1],1))\n",
    "    x = GlobalMaxPool2D()(inp)\n",
    "    out = Dense(nclass, activation=softmax)(x)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=out)\n",
    "    opt = optimizers.Adam(config.learning_rate)\n",
    "\n",
    "    model.compile(optimizer=opt, loss=losses.categorical_crossentropy, metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_2d_conv_model(config):\n",
    "    \n",
    "    nclass = config.n_classes\n",
    "    \n",
    "    inp = Input(shape=(config.dim[0],config.dim[1],1))\n",
    "    x = Convolution2D(32, (4,10), padding=\"same\")(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPool2D()(x)\n",
    "    \n",
    "    x = Convolution2D(32, (4,10), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPool2D()(x)\n",
    "    \n",
    "    x = Convolution2D(32, (4,10), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPool2D()(x)\n",
    "    \n",
    "    x = Convolution2D(32, (4,10), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPool2D()(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(64)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    out = Dense(nclass, activation=softmax)(x)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=out)\n",
    "    opt = optimizers.Adam(config.learning_rate)\n",
    "\n",
    "    model.compile(optimizer=opt, loss=losses.categorical_crossentropy, metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c0c823de-9971-4247-9501-dc74d2f95d8e",
    "_uuid": "d88e90fdc36c77c10ecc8f674d6fd39c8e4d78fb"
   },
   "source": [
    "<a id=\"2d_data\"></a>\n",
    "### Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "eb5aef7d-669b-4cde-9e09-a2bfaa379cc9",
    "_uuid": "70b8cd145ae3838c7974fe257403c8c7fbc8552a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = Config(sampling_rate=44100, audio_duration=2, n_folds=10, \n",
    "                learning_rate=0.001, use_mfcc=True, n_mfcc=40)\n",
    "if not COMPLETE_RUN:\n",
    "    config = Config(sampling_rate=44100, audio_duration=2, n_folds=2, \n",
    "                    max_epochs=1, use_mfcc=True, n_mfcc=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5b9b1c9b-7e02-46f3-96f6-67ebc9bf9132",
    "_uuid": "5242e943f1bc1154d19c03c361a826553c811cfe",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(df, config, data_dir):\n",
    "    X = np.empty(shape=(df.shape[0], config.dim[0], config.dim[1], 1))\n",
    "    input_length = config.audio_length\n",
    "    for i, fname in enumerate(df.index):\n",
    "        print(fname)\n",
    "        file_path = data_dir + fname\n",
    "        data, _ = librosa.core.load(file_path, sr=config.sampling_rate, res_type=\"kaiser_fast\")\n",
    "\n",
    "        # Random offset / Padding\n",
    "        if len(data) > input_length:\n",
    "            max_offset = len(data) - input_length\n",
    "            offset = np.random.randint(max_offset)\n",
    "            data = data[offset:(input_length+offset)]\n",
    "        else:\n",
    "            if input_length > len(data):\n",
    "                max_offset = input_length - len(data)\n",
    "                offset = np.random.randint(max_offset)\n",
    "            else:\n",
    "                offset = 0\n",
    "            data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n",
    "\n",
    "        data = librosa.feature.mfcc(data, sr=config.sampling_rate, n_mfcc=config.n_mfcc)\n",
    "        data = np.expand_dims(data, axis=-1)\n",
    "        X[i,] = data\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c9910de1-388b-470e-8908-6df548f1b866",
    "_uuid": "bb3bc487b52a549a856807dd838a4f6cd209917d"
   },
   "source": [
    "```python\n",
    "X_train = prepare_data(train, config, '../input/freesound-audio-tagging/audio_train/')\n",
    "X_test = prepare_data(test, config, '../input/freesound-audio-tagging/audio_test/')\n",
    "y_train = to_categorical(train.label_idx, num_classes=config.n_classes)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a0e0b17b-d2f8-47f8-9b4d-fff3b2761dde",
    "_uuid": "89e8bd3dc6d1f432309e668685fb98d1ce866e95"
   },
   "source": [
    "<a id=\"2d_normalization\"></a>\n",
    "#### Normalization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "928b0993-7799-4b75-bef8-c1df3755632e",
    "_uuid": "60b6d9dfcb25eb9b3cef7e05675d67b104e24b31"
   },
   "source": [
    "```python\n",
    "mean = np.mean(X_train, axis=0)\n",
    "std = np.std(X_train, axis=0)\n",
    "\n",
    "X_train = (X_train - mean)/std\n",
    "X_test = (X_test - mean)/std\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "af8afd09-66bf-4618-ad95-d70db35b90ec",
    "_uuid": "b70fea949114595111c39f9f64fb1752603e3fdf"
   },
   "source": [
    "<a id=\"2d_training\"></a>\n",
    "#### Training 2D Conv on MFCC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "10fb7477-8122-49fb-be81-1adb7aa45c7f",
    "_uuid": "ab0f2bc7e7bbaced3eb2e4c3acb7c7c63aa73681"
   },
   "source": [
    "```python\n",
    "PREDICTION_FOLDER = \"predictions_2d_conv\"\n",
    "if not os.path.exists(PREDICTION_FOLDER):\n",
    "    os.mkdir(PREDICTION_FOLDER)\n",
    "if os.path.exists('logs/' + PREDICTION_FOLDER):\n",
    "    shutil.rmtree('logs/' + PREDICTION_FOLDER)\n",
    "\n",
    "skf = StratifiedKFold(train.label_idx, n_folds=config.n_folds)\n",
    "for i, (train_split, val_split) in enumerate(skf):\n",
    "    K.clear_session()\n",
    "    X, y, X_val, y_val = X_train[train_split], y_train[train_split], X_train[val_split], y_train[val_split]\n",
    "    checkpoint = ModelCheckpoint('best_%d.h5'%i, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n",
    "    tb = TensorBoard(log_dir='./logs/' + PREDICTION_FOLDER + '/fold_%i'%i, write_graph=True)\n",
    "    callbacks_list = [checkpoint, early, tb]\n",
    "    print(\"#\"*50)\n",
    "    print(\"Fold: \", i)\n",
    "    model = get_2d_conv_model(config)\n",
    "    history = model.fit(X, y, validation_data=(X_val, y_val), callbacks=callbacks_list, \n",
    "                        batch_size=64, epochs=config.max_epochs)\n",
    "    model.load_weights('best_%d.h5'%i)\n",
    "\n",
    "    # Save train predictions\n",
    "    predictions = model.predict(X_train, batch_size=64, verbose=1)\n",
    "    np.save(PREDICTION_FOLDER + \"/train_predictions_%d.npy\"%i, predictions)\n",
    "\n",
    "    # Save test predictions\n",
    "    predictions = model.predict(X_test, batch_size=64, verbose=1)\n",
    "    np.save(PREDICTION_FOLDER + \"/test_predictions_%d.npy\"%i, predictions)\n",
    "\n",
    "    # Make a submission file\n",
    "    top_3 = np.array(LABELS)[np.argsort(-predictions, axis=1)[:, :3]]\n",
    "    predicted_labels = [' '.join(list(x)) for x in top_3]\n",
    "    test['label'] = predicted_labels\n",
    "    test[['label']].to_csv(PREDICTION_FOLDER + \"/predictions_%d.csv\"%i)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4bd794b7-c09e-42d6-8f8a-158758921273",
    "_uuid": "b4421687f65fd8068c04fcdfdb419bf4f08c5f2c"
   },
   "source": [
    "<a id=\"2d_ensembling\"></a>\n",
    "#### Ensembling 2D Conv Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8c253178-6cde-4bad-835d-d09484f381ed",
    "_uuid": "e6868eb538b9fed874fcb02183d2edd348d38b5f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_list = []\n",
    "for i in range(10):\n",
    "    pred_list.append(np.load(\"../input/freesound-prediction-data-2d-conv-reduced-lr/test_predictions_%d.npy\"%i))\n",
    "prediction = np.ones_like(pred_list[0])\n",
    "for pred in pred_list:\n",
    "    prediction = prediction*pred\n",
    "prediction = prediction**(1./len(pred_list))\n",
    "# Make a submission file\n",
    "top_3 = np.array(LABELS)[np.argsort(-prediction, axis=1)[:, :3]]\n",
    "predicted_labels = [' '.join(list(x)) for x in top_3]\n",
    "test = pd.read_csv('../input/freesound-audio-tagging/sample_submission.csv')\n",
    "test['label'] = predicted_labels\n",
    "test[['fname', 'label']].to_csv(\"2d_conv_ensembled_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b67760f2-f8cd-498a-b340-4910d8c443d3",
    "_uuid": "38feef2350dfa3c099bd6fb2e1a0b921716606a8"
   },
   "source": [
    "<a id=\"1d_2d_ensembling\"></a>\n",
    "## <center>5. Ensembling 1D Conv and 2D Conv Predictions</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "12566257-72a5-4aa3-9e11-763c98489810",
    "_uuid": "448e8f9034d9d43a4642b1f441965b272425ba63",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_list = []\n",
    "for i in range(10):\n",
    "    pred_list.append(np.load(\"../input/freesound-prediction-data-2d-conv-reduced-lr/test_predictions_%d.npy\"%i))\n",
    "for i in range(10):\n",
    "    pred_list.append(np.load(\"../input/freesound-prediction-file/test_predictions_%d.npy\"%i))\n",
    "prediction = np.ones_like(pred_list[0])\n",
    "for pred in pred_list:\n",
    "    prediction = prediction*pred\n",
    "prediction = prediction**(1./len(pred_list))\n",
    "# Make a submission file\n",
    "top_3 = np.array(LABELS)[np.argsort(-prediction, axis=1)[:, :3]]\n",
    "predicted_labels = [' '.join(list(x)) for x in top_3]\n",
    "test = pd.read_csv('../input/freesound-audio-tagging/sample_submission.csv')\n",
    "test['label'] = predicted_labels\n",
    "test[['fname', 'label']].to_csv(\"1d_2d_ensembled_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "34e4b1a5-49ac-49ff-a9cd-9b341d784e9b",
    "_uuid": "836b4a9008b4a239f3c41d8f3997bd49fa3c2280"
   },
   "source": [
    "<a id=\"conclusion\"></a>\n",
    "## <center>Results and Conclusion</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1f6bb71f-f461-414c-90d1-725c03f368ff",
    "_uuid": "01cfbfa163adb3da8b7b7da3310fb9e38ce0d478",
    "collapsed": true
   },
   "source": [
    "So far, we have trained two models. Let's analyze their relative complexity and strength.\n",
    "\n",
    "\n",
    "\n",
    "| Model        | Number of Trainable parameters           | Public LB score  |\n",
    "| ------------- |:-------------:| -----:|\n",
    "| 1D Conv on Raw wave      | 360,513 | 0.809 |\n",
    "| 2D Conv on MFCC (verified labels only)    | 168,361  |   0.785 |\n",
    "| 2D Conv on MFCC     | 168,361  |   0.844 |\n",
    "| 1D Conv + 2D Conv Ensemble     | N/A  |   0.895 |\n",
    "\n",
    "**As we can see, 2D Convolution on MFCC performs better than 1D Convolution on Raw waves.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "78397951-3d15-45c1-bc29-17c853d7adf5",
    "_uuid": "b8db90dc506d23d6241c606ca03fd1762f38f36f"
   },
   "source": [
    "## Coming Soon\n",
    "\n",
    "1. Data Augmentation\n",
    "2. Training on Manually Verified Labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
